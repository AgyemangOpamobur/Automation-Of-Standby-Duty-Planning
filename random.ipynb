{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing.preprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m Pipeline\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessor\u001b[39;00m \u001b[39mimport\u001b[39;00m DropFeatures, LogTransformer\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfeature_engine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mencoding\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHotEncoder\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing.preprocessor'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from preprocessing.preprocessor import DropFeatures, LogTransformer\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import data\n",
    "\n",
    "try:\n",
    "    sickness = pd.read_csv(\"sickness_table.csv\", parse_dates=['date'])\n",
    "    # drop the first column\n",
    "    sickness.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    # preview the data\n",
    "    sickness.head()\n",
    "except IOError as err:\n",
    "    print(err)\n",
    "\n",
    "# create lag4 feature from the target\n",
    "sickness['lag_4'] = sickness.sby_need.shift(4) # Shift the target 4 step\n",
    "sickness = sickness.dropna() # Drop the rows with null values\n",
    "\n",
    "# create rolling mean of 7 feature\n",
    "sickness['rolling_mean'] = sickness.sby_need.rolling(7).mean()\n",
    "sickness = sickness.dropna() # Drop the rows with null values\n",
    "sickness.head() # preview the new addition\n",
    "\n",
    "# Make the last 42 days a testset and the remaining days a trainset.\n",
    "# make the date the index\n",
    "sickness = sickness.set_index(sickness.date)\n",
    "X = sickness.drop('sby_need', axis=1) # get the independent variables\n",
    "y = sickness.sby_need # get the target variable\n",
    "step = 42 # Number of days from April16 to May27\n",
    "X_train, X_test = X.iloc[:-step, :],X.iloc[-step:, :]\n",
    "y_train, y_test = y.iloc[:-step], y.iloc[-step:]\n",
    "\n",
    "# check the starting and ending date and the length of the train and testsets.\n",
    "print(f\"Train dates: {X_train.index.min()} --- {X_train.index.max()} (n={len(X_train)})\")\n",
    "print(f\"Test dates: {X_test.index.min()} --- {X_test.index.max()} (n={len(X_test)})\")\n",
    "\n",
    "# Plot the train and test targets\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "y_train.plot(ax=ax, label='train') # plot train data target\n",
    "y_test.plot(ax=ax, label='test') # plot test data target\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# log transform the target\n",
    "y_train = np.log(y_train + 1)\n",
    "y_test = np.log(y_test + 1)\n",
    "\n",
    "# extract date time features\n",
    "# Create function to get German Pubic Holidays\n",
    "def get_holidays():\n",
    "    \"'The function out puts all public holidays in the Federal Republic of Germany from 2016 to 2019.\"\n",
    "    # Import the required libraries\n",
    "    import holidays\n",
    "    from workalendar.europe import Germany\n",
    "    holiday_list = [] # list for all the dates of public holidays\n",
    "    # Get list of public holidays in Germany\n",
    "    for i, v in holidays.Germany(years=[2016, 2017, 2018, 2019]).items():\n",
    "        holiday_list.append(i) # append only the date and not the name\n",
    "    return holiday_list\n",
    "\n",
    "def date_features(df, holiday_list):\n",
    "    '''Perform date operation on pandas dataframe and extract date features'''\n",
    "    df['year'] = df['date'].dt.year.astype(str) # Get year from the date\n",
    "    df['month'] = df['date'].dt.month.astype(str) # get months from the year\n",
    "    df['day'] = df['date'].dt.day.astype(str) # Get days of the month\n",
    "    df['week'] = df['date'].dt.week.astype(str) # Get weeks of the year\n",
    "    df['week_day'] = df['date'].dt.day_name() # Get the days of the week\n",
    "    df['is_weekend'] = df['week_day'].apply(lambda x: 1 if x in ['Sunday', 'Saturday'] else 0).astype(str) # specify if day isweekend or not\n",
    "    df['holidays'] = df['date'].apply(lambda x: 1 if x in holiday_list else 0).astype(str)\n",
    "    df = df.set_index(df.date) # set the date column as index\n",
    "\n",
    "    # drop the date column\n",
    "    df.drop('date', axis=1, inplace=True) # drop the date column\n",
    "    return df # Return a new dataframe with the newly engineered features.\n",
    "\n",
    "# get holidays\n",
    "holidays = get_holidays()\n",
    "# get date features for Trainingset\n",
    "X_train = date_features(X_train, holidays)\n",
    "X_train.head(2)\n",
    "# get date features for Testset\n",
    "X_test = date_features(X_test, holidays)\n",
    "X_test.head(2)\n",
    "# save the X_train,y_train,X_test,y_test for feature selection\n",
    "X_train.to_csv('xtrain.csv', index=False)\n",
    "X_test.to_csv('xtest.csv', index=False)\n",
    "y_train.to_csv('ytrain.csv', index=False)\n",
    "y_test.to_csv('ytest.csv', index=False)\n",
    "\n",
    "# Configuration\n",
    "# categorical variables to encode\n",
    "CATEGORICAL_VARS = ['month', 'week_day',\n",
    "'day', 'year', 'is_weekend', 'holidays']\n",
    "# features to drop\n",
    "REF_VARS = ['week', 'n_duty', 'n_sby', 'dafted']\n",
    "# features to log transform\n",
    "LOG_VARS = ['lag_4', 'rolling_mean']\n",
    "# setup the pipeline\n",
    "sby_need_pipe = Pipeline([\n",
    "\n",
    "    # ====VARIABLE TRANSFORMATION=====\n",
    "    ('log', LogTransformer(LOG_VARS)),\n",
    "    # encode categorical and discrete variables using the target mean\n",
    "    ('categorical_encoder', OneHotEncoder(variables=CATEGORICAL_VARS)),\n",
    "    ('drop_features', DropFeatures(REF_VARS))\n",
    "])\n",
    "\n",
    "# train the pipeline\n",
    "sby_need_pipe.fit(X_train, y_train)\n",
    "# transform x_train\n",
    "X_train = sby_need_pipe.transform(X_train)\n",
    "# transform x_test\n",
    "X_test = sby_need_pipe.transform(X_test)\n",
    "\n",
    "# save pipeline\n",
    "joblib.dump(sby_need_pipe, 'sby_need_pipe')\n",
    "# regression model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_model,'random_forest_model')\n",
    "\n",
    "# evaluate the model:\n",
    "# ====================\n",
    "# make predictions for trainset\n",
    "print('Random ForestModel')\n",
    "print('-'*20)\n",
    "print('Random forest prediction for trainset')\n",
    "print()\n",
    "pred = rf_model.predict(X_train)\n",
    "# determine mse,rmse and r2\n",
    "print('train mse: {}'.format(int(mean_squared_error(np.exp(y_train) - 1, np.exp(pred) - 1))))\n",
    "print('train rmse: {}'.format(int(mean_squared_error(np.exp(y_train) - 1, np.exp(pred) - 1, squared=False))))\n",
    "print('train r2: {}'.format(r2_score(np.exp(y_train) - 1, np.exp(pred) - 1)))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# make predictions for testset\n",
    "print('Random Forestpredictionfortestset')\n",
    "print()\n",
    "pred1 = rf_model.predict(X_test)\n",
    "\n",
    "# determine mse,rmse and r2\n",
    "print('test mse: {}'.format(int(mean_squared_error(np.exp(y_test) - 1, np.exp(pred1) - 1))))\n",
    "print('test rmse: {}'.format(int(mean_squared_error(np.exp(y_test) - 1, np.exp(pred1) - 1, squared=False))))\n",
    "print('test r2: {}'.format(r2_score(np.exp(y_test) - 1, np.exp(pred1) - 1)))\n",
    "\n",
    "# let's evaluate our predictions respect to the sby_need\n",
    "y = np.exp(y_test) - 1 # reverse the log transform of the target\n",
    "y = y.reset_index() # reset the index\n",
    "pred = rf_model.predict(X_test) # get predictions\n",
    "pred = pd.Series(np.exp(pred) - 1) # reverse log transformation\n",
    "\n",
    "# plot\n",
    "# Plot the test and prediction targets\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "y['sby_need'].plot(ax=ax, label='Real') # plot test set\n",
    "pred.plot(ax=ax, label='Predictions') # plot predicted target\n",
    "ax.legend()\n",
    "\n",
    "# Score new data\n",
    "# load the unseen/new dataset\n",
    "data = pd.read_csv('xtest.csv')\n",
    "print(data.head())\n",
    "\n",
    "# check shape\n",
    "print('data shape:', data.shape)\n",
    "\n",
    "# load feature engineering pipeline\n",
    "sby_need_pipe = joblib.load('sby_need_pipe')\n",
    "\n",
    "# load random forest model\n",
    "rf_model = joblib.load('random_forest_model')\n",
    "\n",
    "# transform the dataset with a feature engineering pipeline\n",
    "data = sby_need_pipe.transform(data)\n",
    "\n",
    "# check shape\n",
    "print('Transform datashape:', data.shape)\n",
    "# predict new score\n",
    "prediction = rf_model.predict(data)\n",
    "\n",
    "# print prediction\n",
    "pred = pd.Series(np.exp(prediction) - 1)\n",
    "print(pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30d7fbd599d31bc80c66a3f2788efaff5f39287b44b3f2a0296054be6136b60c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
